{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "na3XXQqwxk4n"
   },
   "source": [
    "# **Concepts Covered:**\n",
    "\n",
    "- <a href = #link6>One Sample T-test for Population Mean $\\mu$</a>\n",
    "- <a href = #link7>Two Independent Sample Z-test for Equality of Means</a>\n",
    "- <a href = #link8>Two Independent Sample T-test for Equality of Means - Equal Std Dev</a>\n",
    "- <a href = #link9>Two Independent Sample T-test for Equality of Means - Unequal Std Dev</a>\n",
    "- <a href = #link16>Paired Sample T-test for Equality of Means</a>\n",
    "- <a href = #link10>One Proportion Z-test</a>\n",
    "- <a href = #link11>Two Proportion Z-test</a>\n",
    "- <a href = #link12>Chi-Square Test for Variance</a>\n",
    "- <a href = #link13>F-test for Equality of Variances</a>\n",
    "- <a href = #link14>Chi-Square Test for Independence</a>\n",
    "- <a href = #link15>One-way ANOVA Test</a>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The parameter 'alternative' has been introduced in the SciPy version 1.6.0. Hence, it is necessary to install the required Scipy version in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the scipy and check the version to be sure that the version is above 1.6.1.\n",
    "import scipy\n",
    "scipy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if the scipy version is lower than 1.6.1, then uncomment the below code to update the scipy package.\n",
    "#!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "n1269wHJF96t"
   },
   "outputs": [],
   "source": [
    "#import the important packages\n",
    "import pandas as pd #library used for data manipulation and analysis\n",
    "import numpy as np # library used for working with arrays.\n",
    "import matplotlib.pyplot as plt # library for plots and visualisations\n",
    "import seaborn as sns # library for visualisations\n",
    "%matplotlib inline \n",
    "\n",
    "import scipy.stats as stats # this library contains a large number of probability distributions as well as a growing library of statistical functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54uwRjj0wK0t"
   },
   "source": [
    "# <a name='link6'>**One Sample T-test for Population Mean $\\mu$**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lpoQOzkw9cb"
   },
   "source": [
    "### Let's revisit the example\n",
    "A certain food aggregator ZYX is facing stiff competition from its main rival SWG during Corona period. To retain business, ZYX is advertising that, within a radius of 5 km from the restaurant where the order is placed, it can still deliver in 40 minutes or less on the average (and changed condition has not made any impact on them). \n",
    "\n",
    "The delivery times in minutes of 25 randomly selected deliveries are given in a CSV file.\n",
    "\n",
    "Assuming the delivery distribution is approximately normal, is there enough evidence that ZYXâ€™s claim is false?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daSTqeX01t1b"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $\\mu$ be the mean delivery time of the ZYX food aggregator.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\mu = 40$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\mu > 40$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhRo1Ebg2_1H"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "jbZ2TScA3NNC",
    "outputId": "7421e4a1-a342-4972-88e4-8b0f557b0351"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Delivery</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>39.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>40.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Delivery  Time\n",
       "0         1  39.4\n",
       "1         2  39.5\n",
       "2         3  39.7\n",
       "3         4  40.7\n",
       "4         5  40.4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastfood = pd.read_csv('FastFood1.csv')\n",
    "fastfood.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZkj8dfp60mY"
   },
   "source": [
    "### Let's test whether the T-test assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - Yes, the delivery time is measured on a continuous scale.\n",
    "\n",
    "*   Normally distributed population and Sample size < 30 - Yes, it is assumed that the population is normal and the sample size is 25 which is less than 30.\n",
    "*   Observations are from a simple random sample - Yes, we are informed that the collected sample a simple random sample.\n",
    "*   Population standard deviation is known - No\n",
    "\n",
    "Voila! We can use T-test for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxeP-6rx7T63"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TRmdVyRM7YUz",
    "outputId": "a5368027-0c61-478d-8d34-d78723d615c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p-value is  1.4822680927543513e-05\n"
     ]
    }
   ],
   "source": [
    "#import the required functions\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "# calculate the test statistic and p-value\n",
    "test_stat, p_value = ttest_1samp(fastfood['Time'], popmean = 40, alternative = 'greater')\n",
    "print('The p-value is ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGVihRGE8RIq"
   },
   "source": [
    "### Insight\n",
    "As the p-value is much less than the level of significance, we can reject the null hypothesis. Hence, we do not have enough significance to conclude that the mean delivery time within 5 km radius is indeed 40 min or less, as claimed by ZYX in their advertisement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23LuDgOiv5JU"
   },
   "source": [
    "\n",
    "\n",
    "# <a name='link7'>**Two Independent Sample Z-test for Equality of Means**</a>\n",
    "\n",
    "### Let's revisit the example\n",
    "\n",
    "To compare customer satisfaction levels of two competing media channels, 150 customers of Channel 1 and 300 customers of Channel 2 were randomly selected and were asked to rate their channels on a scale of 1-5, with 1 being least satisfied and 5 most satisfied (The survey results are summarized in a CSV file). Suppose we know that, $\\sigma_1$ = 0.48 and $\\sigma_2$ = 0.49.\n",
    "\n",
    "Test at 0.05 level of significance whether the data provide sufficient evidence to conclude that channel 1 has a higher mean satisfaction rating than channel 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FD4tTSL2v5i6"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $\\mu_1, \\mu_2$ be the mean customer rating of channel 1 and channel 2 respectively.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\mu_1=\\mu_2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\mu_1>\\mu_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6SHWGjvqZbE"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "QQF4Wfwwqgk2",
    "outputId": "dcf40bef-2661-4503-8e3d-880a41a2bda0"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rating.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4920/2009940771.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rating.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rating.csv'"
     ]
    }
   ],
   "source": [
    "rating = pd.read_csv('rating.csv')\n",
    "rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TKSnS1-r0yk",
    "outputId": "ac87755f-792d-42ee-8a0b-af35ba67a7a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the sample means and sample standard deviations for the two samples\n",
    "print('The mean rating for channel 1 is ' + str(round(rating['channel1_rating'].mean(),1)))\n",
    "print('The mean rating for channel 2 is ' + str(round(rating['channel2_rating'].mean(), 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On9IY1NDv5yJ"
   },
   "source": [
    "\n",
    "\n",
    "### Let's test whether the Z-test assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - The ratings are measured on a continuous scale.\n",
    "* Normally distributed populations or Sample sizes > 30 - Since the sample sizes are greater than 30, Central Limit Theorem states that the distribution of sample means will be normal.\n",
    "* Independent populations - As we are taking samples for two different channels, the two samples are from two independent populations.\n",
    "* Known population standard deviation $\\sigma_1$ and $\\sigma_2$ - Yes, we know the population standard deviations of both the populations.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.\n",
    "\n",
    "Voila! We can use two sample Z-test for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPyf-mDIqqTk"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user-defined function to compare the equality of two means from two independent populations, where population standard deviations are known\n",
    "# this function returns the p-value for one tailed test\n",
    "# for two-tailed test, multiply the p-value by 2\n",
    "# To know more about the derivation of test statistic and standard error formula, please refer to the monographs and additional materials\n",
    "def ztest_2samp(X1, X2, pop_sd1, pop_sd2, n1, n2):\n",
    "    '''\n",
    "    X1 - first of the two independent samples (sample 1)\n",
    "    X2 - second of the two independent samples (sample 2)\n",
    "    pop_sd1 - population standard deviation of sample 1\n",
    "    pop_sd2 - population standard deviation of sample 2\n",
    "    n1 - size of sample 1\n",
    "    n2 - size of sample 2\n",
    "    '''\n",
    "    from numpy import sqrt, abs # import the required functions\n",
    "    from scipy.stats import norm # import the required function\n",
    "    se = sqrt(pop_sd1**2/n1 + pop_sd2**2/n2) # calculate the standard error\n",
    "    test_stat = ((X1.mean() - X2.mean()) - 0)/ se # calculate the test statistic\n",
    "    pval = 1 - norm.cdf(abs(test_stat)) # calculate the one-tailed p-value\n",
    "    return pval # return the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a_KDzzbLrXc6",
    "outputId": "09e5913f-4576-4b78-9aa2-ee9ac814b51a"
   },
   "outputs": [],
   "source": [
    "# find the p-value using the ztest_2samp() function\n",
    "p_value = ztest_2samp(rating['channel1_rating'].dropna(), rating['channel2_rating'], 0.48, 0.49, 150 ,300)\n",
    "print('The P-value is', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6YUHgI3hxjrC"
   },
   "source": [
    "### Insight\n",
    "\n",
    "As the p-value is much less than the level of significance 0.05, we reject the null hypothesis. Thus, we have enough statistical evidence to say that channel 1 has a higher mean satisfaction rating than channel 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gE3YTnBx54pI"
   },
   "source": [
    "# <a name='link8'>**Two Independent Sample T-test for Equality of Means - Equal Std Dev**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2VX0ny4f6a_B"
   },
   "source": [
    "\n",
    "### Let's revisit the example\n",
    "\n",
    "\n",
    "In the lockdown period, because of working from home and increased screen time, many opted for listening to FM Radio for entertainment rather than watching Cable TV. An advertisement agency randomly collected daily usage time data (in minutes) from both type of users and stored it in a CSV file.\n",
    "\n",
    "Assuming daily Radio and TV usage time are normally distributed, do we have enough evidence to conclude that there is any difference between daily TV and Radio usage time at 0.05 significance level?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQI62wCl9JEB"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $\\mu_1, \\mu_2$ be the daily mean Radio usage time and TV usage time respectively.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\mu_1=\\mu_2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\mu_1\\neq\\mu_2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bq06ETuCYEey"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "v63O6W_byo2Z",
    "outputId": "5c0b668b-d895-4080-bdaa-6fc222550ecd"
   },
   "outputs": [],
   "source": [
    "tvradio = pd.read_csv('TVRadio.csv')\n",
    "tvradio.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aJjplEcBXvnQ",
    "outputId": "5937a89e-e860-439e-bedd-fb38fc8470fc"
   },
   "outputs": [],
   "source": [
    "# find the sample means and sample standard deviations for the two samples\n",
    "print('The mean usage time of cable TV is ' + str(tvradio['Cable_TV'].mean()))\n",
    "print('The mean usage time of FM radio is ' + str(tvradio['FM_Radio'].mean()))\n",
    "print('The standard deviation of usage time of cable TV is ' + str(round(tvradio['Cable_TV'].std(),2)))\n",
    "print('The standard deviation of usage time of FM radio is ' + str(round(tvradio['FM_Radio'].std(),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZTenzwH-I6f"
   },
   "source": [
    "### Let's test whether the T-test assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - Yes, the usage time is measured on a continuous scale.\n",
    "* Normally distributed populations - Yes, we are informed that the populations are assumed to be normal.\n",
    "* Independent populations - As we are taking random samples for two different type of users, the two samples are from two independent populations.\n",
    "* Equal population standard deviations - As the sample standard deviations are almost equal, the population standard deviations may be assumed to be equal.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.\n",
    "\n",
    "Voila! We can use two sample T-test for this problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaXBN9zP6rFH"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XaRGog9D8_it",
    "outputId": "543549fc-5f47-4675-db4b-fbe2a5f2181b"
   },
   "outputs": [],
   "source": [
    "#import the required functions\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# find the p-value\n",
    "test_stat, p_value = ttest_ind(tvradio['Cable_TV'], tvradio['FM_Radio'], equal_var = True, alternative = 'two-sided')\n",
    "print('The p-value is ' + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU8OiJM1bTMJ"
   },
   "source": [
    "### Insight\n",
    "As the p-value(~0.55) is much greater than the level of significance, we can not reject the null hypothesis. Hence, we do not have enough significance to conclude that there is any difference between daily TV and Radio usage at 0.05 significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S94HHmoe6Hlv"
   },
   "source": [
    "# <a name='link9'>**Two Independent Sample T-test for Equality of Means - Unequal Std Dev**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GF0J8cvZb_6Q"
   },
   "source": [
    "\n",
    "\n",
    "### Let's revisit the example\n",
    "\n",
    "SAT verbal scores of two groups of students are given in a CSV file. The first group, College, contains scores of students whose parents have at least a bachelor's degree and the second group, High School, contains scores of students whose parents do not have any college degree.\n",
    "\n",
    "The Education Department is interested to know whether the sample data support the theory that students show a higher population mean verbal score on SAT if their parents attain a higher level of education.\n",
    "\n",
    "Assuming SAT verbal scores for two populations are normally distributed, do we have enough statistical evidence for this at 5% significance level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJuoxHuSeiZW"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "\n",
    "\n",
    "Let $\\mu_1, \\mu_2$ be the mean SAT verbal scores of **College** and **High School** groups respectively.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\mu_1=\\mu_2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\mu_1>\\mu_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6PL8Qg6hc5I"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Zw4bSIVzwO7p",
    "outputId": "f8b41f17-aa36-4d3f-a34a-ea8517448be3"
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "satscore = pd.read_csv('SATVerbal1.csv')\n",
    "satscore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5ZaAJuwwslO",
    "outputId": "41869062-b024-42a2-91a1-f19f0162aaae"
   },
   "outputs": [],
   "source": [
    "# find the sample means and sample standard deviations for the two samples\n",
    "print('The mean SAT verbal score for College group is ' + str(satscore['College'].mean()))\n",
    "print('The mean SAT verbal score for High School group is ' + str(satscore['High School'].mean()))\n",
    "print('The standard deviation of SAT verbal score for College group is ' + str(round(satscore['College'].std(), 2)))\n",
    "print('The standard deviation of SAT verbal score for High School group is ' + str(round(satscore['High School'].std(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "llTtGBvx6WeR"
   },
   "source": [
    "### Let's test whether the T-test assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - Yes, the SAT score is measured on a continuous scale.\n",
    "* Normally distributed populations - Yes, we are informed that the populations are assumed to be normal.\n",
    "* Independent populations - As we are taking random samples for two different groups, the two samples are from two independent populations.\n",
    "* Unequal population standard deviations - As the sample standard deviations are different, the population standard deviations may be assumed to be different.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample a simple random sample.\n",
    "\n",
    "Voila! We can use two sample T-test for this problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FLK0t0VL6vMg"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXKIJXB66wCU",
    "outputId": "dd97f539-b0c1-48fd-b7dd-baf49f6af4ef"
   },
   "outputs": [],
   "source": [
    "#import the required functions\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# find the p-value\n",
    "test_stat, p_value = ttest_ind(satscore['College'], satscore['High School'].dropna(), equal_var = False, alternative = 'greater')\n",
    "print('The p-value is ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xvyDESl8GXn"
   },
   "source": [
    "### Insight\n",
    "As the p-value (~0.008) is less than the level of significance, we can reject the null hypothesis. Hence, we do have enough evidence to support the claim that students show a higher population mean verbal score on SAT if their parents attain a higher level of education."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8JUAO2IjvNyb"
   },
   "source": [
    "# <a name='link16'>**Paired Sample T-test for Equality of Means**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sK3hszBz2kFZ"
   },
   "source": [
    "### Let's revisit the example\n",
    "Typical prices of single-family homes in Florida are given for a sample of 15 metropolitan areas (in 1000 USD) for 2002 and 2003 in a CSV file.\n",
    " \n",
    "Assuming the house prices are normally distributed, do we have enough statistical evidence to say that there is an increase in the house price in one year at 0.05 significance level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6oqinL-6-JW"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "\n",
    "Let $\\mu_1, \\mu_2$ be the mean price of single-family homes in metropolitan areas of Florida for 2002 and 2003 respectively.\n",
    "\n",
    "We want to test whether there is an increase in the house price from 2002 to 2003.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\mu_1=\\mu_2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\mu_1<\\mu_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Bi_wT8h8_A1"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "z47av-s1Arni",
    "outputId": "3c3c0aed-cdcd-4917-cbd0-8686bc2c10d8"
   },
   "outputs": [],
   "source": [
    "# import the data\n",
    "houseprice = pd.read_csv('Florida.csv')\n",
    "houseprice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IE49UrKBjpO",
    "outputId": "b28cd84d-1747-453a-f9fb-2a7e1136035c"
   },
   "outputs": [],
   "source": [
    "# find the mean difference between the house prices from 2003 to 2002\n",
    "# the aim behind finding this difference is to check there is really an increase in the house price from 2002 to 2003.\n",
    "diff = np.mean(houseprice['Jan_2003'] - houseprice['Jan_2002'])\n",
    "print('The mean of the differences between the house prices from 2003 to 2002', diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZKt050TClTi"
   },
   "source": [
    "### Let's test whether the paired T-test assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - Yes, the house price is measured on a continuous scale.\n",
    "* Normally distributed populations - Yes, we are informed that the populations are assumed to be normal.\n",
    "* Independent observations - As we are taking the sampled unit randomly, the observed units are independent.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.\n",
    "\n",
    "Voila! We can use paired sample T-test for this problem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geoF6g58DIpN"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b_OSS4ljDL4V",
    "outputId": "e044ece9-46a9-4bad-d4cb-1c206855de67"
   },
   "outputs": [],
   "source": [
    "#import the required functions\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "# find the p-value\n",
    "test_stat, p_value = ttest_rel(houseprice['Jan_2002'], houseprice['Jan_2003'], alternative = 'less')\n",
    "print('The p-value is ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2ZLqCVRKeO8"
   },
   "source": [
    "### Insight\n",
    "As the p-value is much less than the level of significance, the null hypothesis can be rejected. Thus, it may be concluded that there is enough statistical evidence to conclude that there is an increase in the price from 2002 to 2003."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fKq990WGyjJ"
   },
   "source": [
    "\n",
    "# <a name='link10'>**One Proportion Z-test**</a>\n",
    "\n",
    "### Let's revisit the example\n",
    "\n",
    "A researcher claims that Democratic party will win in the next United States Presidential election. \n",
    "\n",
    "To test her belief the researcher randomly surveyed 90 people and 24 out of them said that they voted for Democratic party. \n",
    "\n",
    "Is there enough evidence at ð›‚ = 0.05 to support this claim?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TR0HTVFNP0rI"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $p$ be the proportion of people who voted for Democratic party.\n",
    "\n",
    "The researcher will test the null hypothesis\n",
    "\n",
    ">$H_0:p \\leq 0.5$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:p > 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mVMkj0EQ4sW"
   },
   "source": [
    "### Let's test whether the Z-test assumptions are satisfied or not\n",
    "\n",
    "*   Binomally distributed population - Yes, people either vote for Democratic or Republic party\n",
    "*   Random sampling from the population - Yes, the researcher conducted a random survey\n",
    "*   Can the binomial distribution approximated to normal distribution - Yes. For binary data, CLT works slower than usual. The standard thing is to check whether np and n(1-p) are greater than or equal to 10. Here, n and p refer to the sample size and sample proportion respectively. \n",
    ">$np = 90\\cdot \\frac{24}{90} =24 \\geq 10\\\\\n",
    "n(1-p) = 90 \\cdot \\frac{90-24}{90} =66 \\geq 10$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUf9drG-ZzQV"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kj47KnHHYZov",
    "outputId": "4ff2c38a-e403-4cbd-973b-1963cfa0827c"
   },
   "outputs": [],
   "source": [
    "# import the required fuction\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# find the p-value\n",
    "test_stat, p_value = proportions_ztest(24, 90, value = 0.5, alternative = 'larger')\n",
    "print('The p-value is ' + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdpMB1Qocutc"
   },
   "source": [
    "### Insight\n",
    "\n",
    "As the p-value is much greater than the significance level 0.05, we can not reject the null hypothesis. Thus, the researcher do not have enough statistical significance to claim that Democratic party will win in the next United States Presidential election at 5% significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WvHJiRuF6guQ"
   },
   "source": [
    "# <a name='link11'>**Two Proportion Z-test**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn-dYLgzF69x"
   },
   "source": [
    "### Let's revisit the example\n",
    "\n",
    "A car manufacturer aims to improve its products' quality by reducing the defects. So, the manufacturer randomly checks the efficiency of two assembly lines in the shop floor. In line 1, there are 20 defects out of 200 samples and In line 2, there are 25 defects out of 400 samples. \n",
    "\n",
    "At 5% level of significance, do we have enough statistical evidence to conclude that the two assembly procedures are different?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YCkHK12HreW"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $p_1,p_2$ be the proportions of defects in assembly line 1 and line 2 respectively.\n",
    "\n",
    "The manufacturer will test the null hypothesis\n",
    "\n",
    ">$H_0:p_1 =p_2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:p_1 \\neq p_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c5hHivhKZUM"
   },
   "source": [
    "### Let's test whether the Z-test assumptions are satisfied or not\n",
    "\n",
    "*   Binomally distributed population - Yes, a product is either defective or non-defective.\n",
    "*   Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.  \n",
    "*   Can the binomial distribution approximated to normal distribution - Yes. For binary data, CLT works slower than usual. The standard thing is to check whether np and n(1-p) are greater than or equal to 10. Here, n and p refer to the sample size and sample proportion respectively.\n",
    ">$np_1 = 200\\cdot \\frac{20}{200} =20 \\geq 10\\\\\n",
    "n(1-p_1) = 200 \\cdot \\frac{200-20}{200} =180 \\geq 10 \\\\\n",
    "np_2 = 400\\cdot \\frac{25}{400} =25 \\geq 10\\\\\n",
    "n(1-p_2) = 400 \\cdot \\frac{400-25}{375} =375 \\geq 10 $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHGP8KFiLdJ2"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EoLlJA4LkzN",
    "outputId": "9054fa4e-cd88-4d38-adcc-8e2be79690a5"
   },
   "outputs": [],
   "source": [
    "# import the required fuction\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "# set the counts of defective items\n",
    "defect_count = np.array([20, 25])\n",
    "\n",
    "# set the sample sizes\n",
    "nobs = np.array([200, 400])\n",
    "\n",
    "# find the p-value\n",
    "test_stat, p_value = proportions_ztest(defect_count, nobs)\n",
    "print('The p-value is ' + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVjQs0SWNQQv"
   },
   "source": [
    "### Insight\n",
    "\n",
    "As the p-value is greater than the significance level 0.05, we can not reject the null hypothesis. Thus, the manufacturer do not have enough statistical significance to conclude that the two assembly procedures are different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qc1Cy9re6q1w"
   },
   "source": [
    "# <a name='link12'>**Chi-Square Test for Variance**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9tlnF6ZXOvM"
   },
   "source": [
    "\n",
    "\n",
    "### Let's revisit an example\n",
    "It is conjectured that the standard deviation for the annual return of mid cap mutual funds is 22.4%, when all such funds are considered and over a long period of time. The sample standard deviation of a certain mid cap mutual fund based on a random sample of size 32 is observed to be 26.4%. \n",
    "\n",
    "Do we have enough evidence to claim that the standard deviation of the chosen mutual fund is greater than the conjectured standard deviation for mid cap mutual funds at 0.05 level of significance?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgP0uEqFflBw"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $\\sigma$ be the average standard deviation of the mutual funds.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\sigma^2 = 22.4^2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\sigma^2 > 22.4^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yYWQiK5Ehtug"
   },
   "source": [
    "### Let's test whether the assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - Yes\n",
    "* Normally distributed population - Since the sample sizes are greater than 30, Central Limit Theorem states that the distribution of sample means will be normal.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbH-SLqriUcm"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jso7skFviYr2",
    "outputId": "f47c0232-3ce3-4974-b3f2-d79b875c1ee1"
   },
   "outputs": [],
   "source": [
    "#import the required function\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# user-defined function to get the test stat and p-value\n",
    "# To know more about the derivation of test statistic formula, please refer to the monographs and additional materials\n",
    "def chi_var(pop_var, sample_var, n):\n",
    "  # calculate the test statistic\n",
    "  test_stat = (n - 1) * sample_var / pop_var\n",
    "  # calculate the p-value\n",
    "  p_value = 1 - chi2.cdf(test_stat, n-1)\n",
    "  return (test_stat, p_value)\n",
    "\n",
    "# set the value of sample size\n",
    "n = 32\n",
    "# set the values of population and sample variance\n",
    "sigma_2, s_2 = 22.4**2, 26.4**2\n",
    "\n",
    "test_stat, p_value = chi_var(sigma_2, s_2, n)\n",
    "\n",
    "print('The p-value is ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37fXFQTln_5r"
   },
   "source": [
    "### Insight\n",
    "As the p-value is greater than the significance level, we can not reject the null hypothesis. Hence, we do not have enough statistical significance to conclude that the standard deviation of the chosen mutual fund is greater than the average standard deviation for mid cap mutual funds at 0.05 level of significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFROKrmE6975"
   },
   "source": [
    "# <a name='link13'>**F-test for Equality of Variances**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cIrDvcq5f1-"
   },
   "source": [
    "\n",
    "\n",
    "### Let's revisit the example\n",
    "\n",
    "The variance of a process is an important quality of the process. A large variance implies that the process needs better control and there is opportunity to improve. \n",
    "\n",
    "\n",
    "The data (Bags.csv) includes weights for two different sets of bags manufactured from two different machines. It is assumed that the weights for two sets of bags follow normal distribution.\n",
    "\n",
    "Do we have enough statistical evidence at 5% significance level  to conclude that there is a significant difference between the variances of the bag weights for the two machines.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KupIZV2zDhmT"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "Let $\\sigma_1^2, \\sigma_2^2$ be the variances of weights of the bags produced by two different machines.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:\\sigma_1^2 = \\sigma_2^2$\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:\\sigma_1^2 \\neq \\sigma_2^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibuZ0DGDIEuW"
   },
   "source": [
    "### Let's test whether the assumptions are satisfied or not\n",
    "\n",
    "* Continuous data - Yes, the weight is measured on a continuous scale.\n",
    "* Normally distributed populations - Yes, it is assumed that the populations are normally distributed.\n",
    "* Independent populations - As the two sets of bags are manufactured from two different machines, the populations are independent.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7_5T3R_IoM3"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7hU-UWjSbM2d",
    "outputId": "9bd92397-ce33-487e-d27f-5c7b3ddb897f"
   },
   "outputs": [],
   "source": [
    "bagweight = pd.read_csv('Bags.csv')\n",
    "bagweight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LI-d8TAblYi"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QqPr1D8KbqOq",
    "outputId": "ae5234dd-0f5a-4895-ad30-236d8302becb"
   },
   "outputs": [],
   "source": [
    "# import the required function\n",
    "from scipy.stats import f\n",
    "\n",
    "# user-defined function to perform F-test\n",
    "# To know more about the derivation of test statistic formula, please refer to the monographs and additional materials\n",
    "def f_test(x, y):\n",
    "  x = np.array(x)\n",
    "  y = np.array(y) \n",
    "  test_stat = np.var(x, ddof=1)/np.var(y, ddof=1) #calculate F test statistic \n",
    "  dfn = x.size-1 #define degrees of freedom numerator \n",
    "  dfd = y.size-1 #define degrees of freedom denominator \n",
    "  p = (1 - f.cdf(test_stat, dfn, dfd)) # find p-value of F test statistic \n",
    "  p1 = p*2 # Converting one-tail to two-tail test \n",
    "  return(print(\"The p_value is {}\" .format(round(p,8)))) \n",
    "\n",
    "#perform F-test \n",
    "f_test(bagweight.dropna()['Machine 1'], bagweight.dropna()['Machine 2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CUHnA3-hdvMO"
   },
   "source": [
    "### Insight\n",
    "As the p-value is much smaller than the level of significance, the null hypothesis can be rejected. Hence, we have enough statistical evidence to conclude that there is a difference between the bag weights for the two machines at 0.05 significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xnmLq677KkA"
   },
   "source": [
    "# <a name='link14'>**Chi-Square Test for Independence**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mU0SDjKyeUcR"
   },
   "source": [
    "### Let's revisit the example\n",
    "\n",
    "The beverage preference data for different age groups has given in the Beverage.csv file.\n",
    "\n",
    "Do we have enough statistical evidence to conclude that beverage preference depend on age.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqjXDxvwe-Io"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "D5ADnSRofStd",
    "outputId": "914f83a3-86f0-4e3c-a72e-582b59e2180c"
   },
   "outputs": [],
   "source": [
    "beverage = pd.read_csv('Beverage.csv')\n",
    "beverage.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BL1dzNufjcm"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:$ Beverage preference is independent of age.\n",
    "\n",
    "against the alternate hypothesis\n",
    "\n",
    ">$H_a:$ Beverage preference depends on age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITiDm4GMgEnt"
   },
   "source": [
    "### Let's test whether the assumptions are satisfied or not\n",
    "\n",
    "* Categorical variables - Yes\n",
    "* Expected value of the number of sample observations in each level of the variable is at least 5 - Yes, the number of observations in each level is greater than 5.\n",
    "* Random sampling from the population - Yes, we are informed that the collected sample is a simple random sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "no52O-10HQ4h"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qUPCXOomHXX7",
    "outputId": "81262c25-558d-4bff-821a-267356150f0d"
   },
   "outputs": [],
   "source": [
    "# import the required function\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# find the p-value\n",
    "chi, p_value, dof, expected = chi2_contingency(beverage.drop('Age', axis = 1))\n",
    "print('The p-value is', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAb4fDcmJIpQ"
   },
   "source": [
    "### Insight\n",
    "As the p-value is much less than the significance level, we can reject the null hypothesis. Hence, we do have enough statistical significance to conclude that beverage preference is not independent of age at 5% significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZLntwM_WcK2"
   },
   "source": [
    "# <a name='link15'>**One-way ANOVA Test**</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxvEn474b25J"
   },
   "source": [
    "### Let's revisit the example\n",
    "\n",
    "Traffic management inspector in a certain city wants to understand whether carbon emissions from different cars are different. The inspector has reasons to believe that Fuel type may be the factors responsible for differences in carbon emission.\n",
    "\n",
    "For this purpose, the inspector has taken random samples from all registered cars on the road in that city and would like to test if the amount of carbon emission release depends on fuel type at 5% significance level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFMixr_Af40Q"
   },
   "source": [
    "### Let's have a look on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "ab3mUcIxgKeH",
    "outputId": "7b2cd5d7-4648-4ddd-d234-ddd3f72f9c44"
   },
   "outputs": [],
   "source": [
    "aovdata = pd.read_csv('AOVData.csv')\n",
    "aovdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cr_N3sAeoqeO"
   },
   "source": [
    "Here, co_emissions is the response and fuel_type is the factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1zyATPm47v6N",
    "outputId": "264b5235-20f1-4b9a-8638-0ad36bff4792"
   },
   "outputs": [],
   "source": [
    "# get the levels of factor fuel_type\n",
    "aovdata['fuel_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j63R8Uh78C-w"
   },
   "source": [
    "### Let's write the null and alternative hypothesis\n",
    "\n",
    "Let $\\mu_1, \\mu_2, \\mu_3$ be the means of carbon dioxide emissions for fuel type E85, LPG and Petrol respectively.\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0: \\mu_1 = \\mu_2 = \\mu_3$\n",
    "\n",
    "against the alternative hypothesis\n",
    "\n",
    ">$H_a: $ At least one carbon emission level is different from the rest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "WE2FRb1a9Gxs",
    "outputId": "baa8c2ce-a8c5-45bb-e6cc-03cc334d5165"
   },
   "outputs": [],
   "source": [
    "# mean of carbon emission at different levels of the fuel_type factor\n",
    "print(aovdata.groupby(\"fuel_type\")[\"co_emissions\"].mean())\n",
    "\n",
    "# draw the boxplot for visualization \n",
    "fig, ax = plt.subplots(figsize = (6,6))\n",
    "a = sns.boxplot(x= \"fuel_type\", y = 'co_emissions' , data = aovdata, hue = 'fuel_type')\n",
    "a.set_title(\"Carbon Emission w.r.t. Fuel type (3 levels)\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qb-sMEm2WtHf"
   },
   "source": [
    "Now, the normality and equality of variance assumptions need to be checked. \n",
    "\n",
    "* For testing of normality, Shapiro-Wilkâ€™s test is applied to the response variable.\n",
    "\n",
    "* For equality of variance, Levene test is applied to the response variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pFdvUuGC6qu"
   },
   "source": [
    "### Shapiro-Wilkâ€™s test\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0:$ Carbon emission follows a normal distribution against\n",
    "\n",
    "against the alternative hypothesis\n",
    "\n",
    ">$H_a:$ Carbon emission does not follow a normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yHZdbI6hClTY",
    "outputId": "43d972c7-63e0-4376-947a-2e22bacfb23a"
   },
   "outputs": [],
   "source": [
    "# Assumption 1: Normality\n",
    "# import the required function\n",
    "from scipy import stats\n",
    "\n",
    "# find the p-value\n",
    "w, p_value = stats.shapiro(aovdata['co_emissions']) \n",
    "print('The p-value is', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1-_8Mi2EYIU"
   },
   "source": [
    "Since p-value of the test is very large, we fail to reject the null hypothesis that the response follows the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RN7l8dkREpFu"
   },
   "source": [
    "### Leveneâ€™s test\n",
    "\n",
    "We will test the null hypothesis\n",
    "\n",
    ">$H_0$: All the population variances are equal\n",
    "\n",
    "against the alternative hypothesis\n",
    "\n",
    ">$H_a$: At least one variance is different from the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jj-jsFGTFKtI",
    "outputId": "b6247937-9127-4bbe-c677-b78eaf5652ce"
   },
   "outputs": [],
   "source": [
    "#Assumption 2: Homogeneity of Variance\n",
    "#import the required function\n",
    "from scipy.stats import levene\n",
    "statistic, p_value = levene( aovdata['co_emissions'][aovdata['fuel_type']==\"Petrol\"], \n",
    "                                   aovdata['co_emissions'][aovdata['fuel_type']==\"E85\"], \n",
    "                                   aovdata['co_emissions'][aovdata['fuel_type']==\"LPG\"])\n",
    "# find the p-value\n",
    "print('The p-value is', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6NjQ3iCF7tj"
   },
   "source": [
    "Since the p-value is large, we fail to reject the null hypothesis of homogeneity of variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvMMknJDq_LU"
   },
   "source": [
    "### Let's test whether the assumptions are satisfied or not\n",
    "\n",
    "* The populations are normally distributed - Yes, the normality assumption is verified using the Shapiro-Wilkâ€™s test.\n",
    "* Samples are independent simple random samples - Yes, we are informed that the collected sample is a simple random sample.\n",
    "* Population variances are equal - Yes, the homogeneity of variance assumption is verified using the Levene's test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXyl5ApFr6zU"
   },
   "source": [
    "### Let's find the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HRjKGT13ryta",
    "outputId": "833aa1ea-cacd-4383-cac0-d463e585fc9c"
   },
   "outputs": [],
   "source": [
    "#import the required function\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# perform one-way anova test\n",
    "test_stat, p_value = f_oneway(aovdata.loc[aovdata['fuel_type'] == 'Petrol', 'co_emissions'],\n",
    "                              aovdata.loc[aovdata['fuel_type'] == 'E85', 'co_emissions'],\n",
    "                              aovdata.loc[aovdata['fuel_type'] == 'LPG', 'co_emissions'])\n",
    "print('The p-value is ' + str(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4Zat_fyvV3j"
   },
   "source": [
    "### Insight\n",
    "As the p-value is much less than the significance level, we can reject the null hypothesis. Hence, we do have enough statistical significance to conclude that  at least one carbon emission level is different from the rest at 5% significance level.\n",
    "\n",
    "However, we don't know which mean is different from the rest or whether all pairs of means are different. Multiple comparison tests are used to test the differences between all pairs of means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lb7fV6waiIb8"
   },
   "source": [
    "### Multiple Comparison test (Tukey HSD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In order to identify for which fuel type mean carbon emission is different from other groups, the null hypothesis is\n",
    "\n",
    "  > $ð»_0: ðœ‡_1=ðœ‡_2 \\text{ and } ðœ‡_1=ðœ‡_3 \\text{ and } ðœ‡_2=ðœ‡_3$\n",
    "\n",
    "against the alternative hypothesis\n",
    "\n",
    " > $ð»_a: ðœ‡_1\\neqðœ‡_2 \\text{ or } ðœ‡_1\\neqðœ‡_3 \\text{ or } ðœ‡_2\\neqðœ‡_3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the required function\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "m_comp = pairwise_tukeyhsd(endog = aovdata['co_emissions'], groups = aovdata['fuel_type'], alpha = 0.05)\n",
    "print(m_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insight\n",
    "\n",
    "As the p-values (refer to the p-adj column) for comparing the mean carbon emissions for the pair E85-LPG and E85-Petrol is less than the significance level, the null hypothesis of equality of all population means can be rejected.\n",
    "\n",
    "Thus, we can say that the mean carbon emission for Petrol and LPG is similar but emission for fuel type E85 is significantly different from LPG and Petrol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------**The End**-------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Notebook Week2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
